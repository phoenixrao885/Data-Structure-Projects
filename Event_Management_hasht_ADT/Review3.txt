Efficiency review for Program # 3 by Tejas Menon, CS163, edited last on 22/5.

1) Evaluation of the data structure used currently

A hashtable to store and retrieve data was the best choice for implemetation with this program I believe, since we dealt with a large quantity of data and required some form of 'sieving' through a bulk of this dataset at a time to allow for searches that could be performed under reasonable time constraints. Since displaying the data in any specific order or retrieving data within a certain range wasn't a necessity, we could safely assume that a hashtable would provide us all the benefits of direct access while we neglected its drawbacks. Regarding insertion, it was interesting how the hashfunction facilitated a 'random distribution' between all the indexes of a hashtable while maintaining an equal accessibility for all that we added. Another notable feature that this program highlighted about computing was the memory vs processing speed conundrum, where we could experience how increased memory allowances meant faster retrieval with lesser collisions while little memory meant that retrieval speeds suffered and collisions increased. Due to the relatively small size of the data we had available, I could not measurably experience any differences in retrievals between a hashtable size of 1 and 1000, but I believe I could have used clock time functions from the <ctime> library to accurately measure and represent the differences. A challenging task I encountered in this program was deallocating the data for the remove_before function, where I needed to ensure I did not perform multiple deallocations on the same event, a task for which I devised two solutions- one of O(n^2) time complexity and another of O(n). The first solution required me to store deallocated event addresses in an array and cross check this value with every node to be deallocated - a process that would have taken incrementally longer with every deallocation. Also, we would have needed to know the maximum amount of events to be stored in the hashtable at runtime so that we could allocate an array size of appropriate length. The viability of constructing such an array for a large number of events and confirming the client would abide by this value would have been unrealistic expectations due to which I went forward with my second solution that although was more complex, offered a constant time algorithm. The second solution required running the hash function for every keyword in every event and then performing a deallocation only at the index of the last keyword. This meant that we could couple the direct access performance of the hashtable with the destructor function and therefore enable deallocation to become a linear process, with the time required for a single deallocation only being multiplied by 'a' - the number of keywords. 

2) Drawbacks of my current data structure

The hashtable inherently becomes an unsuitable data structure for displaying multiple entries of data or displaying 'similar' results as data connected within short proximity of one another are always randomized and bear no similarities with one another other than mapping to the same index. This means that very exact information regarding the stored data needs to be available or a hashtable would be unhelpful for retrieval. Additionally, one also creates many copies of the data pointers during each insertion that could have been memory used elsewhere, and this results in an overcomplicated removal process that could be potentially as time consuming as retrieval would have been in another data structure. 

A workaround that would allow a hashtable to contain results relevant to their neighbours could be achieved by perfecting the hashfunction such that data similar to one another (in most cases) end up close (or share some logical relationship) which we can utilize to infer meaning from the data.