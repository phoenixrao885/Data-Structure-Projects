Efficiency review for Program # 4 by Tejas Menon, CS163, edited last on 6/2.

1) Evaluation of the data structure used currently

As compared to the previous data structure used to implement this program, the BST had several benefits, both functionally and algorithmically. From the functional standpoint, one could now view their results in sorted order as the BST always inserted events in that order and when compared to the LLL, retrievals were much quicker, to a maximum factor of approximately log(2)(n) assuming that the tree was more or less balanced. I could also confirm that the tree was relatively balanced as its height was 13 while the total amount of data items inputted was 73. (Max items for that height is (2^15-1) which is obviously larger but decreasing the height by just 7 brings down the max possible nodes to less than 73). Also, since each event was only stored in the tree once, pointers to events weren’t required  and the removal and insertion algorithms were relatively simple as there was no need for precautionary measures to check for pointers already deallocated. My particular deallocation algorithm was very simple, as a node destructor could be used where the left and right pointers would be deallocated if it wasn’t NULL, and therefore achieve a deallocation of the entire BST in just two lines of code. The most challenging function to write and comprehend in this program was the remove_key() function, where I needed to remove every event containing the keyword in a single traversal. What proved helpful here was using the remove_title() in this function, into which I could simply pass the pointer to the node and its title to be removed. And because all the events were uniquely arranged by title in the BST, I could expect no problems with duplicate events. 
Also notably, debugging code in this program was very simple as I didn’t need to rely on hash values to find where errors lay. The memory requirement for the BST was also lesser, as I didn’t need to store multiple pointers to events and didn’t need to allocate a large hashtable of node pointers. Another aspect of BST’s that we could possibly find beneficial for expansion would be the logical relations it shares with its siblings and children, and the fact that any potential function can use the values around a particular node to offer suggestions in case a user doesn’t type the exact keywords. In essence, the inexactness of the BST would allow for more user friendliness. 
Although the hashtable could possibly be more beneficial for very large datasets (in millions) since the access time would more or less be constant O(1) for a large enough array size, there could be problems allocating a large enough array in the first place. And if a small size is chosen due to this, there could possibly be large time consumptions in traversing through the collision resolution chain. Therefore, I believe that the BST would have been a better option for the size of data we needed to add.


2) Drawbacks of my current data structure

The drawbacks with the BST for this program would most possibly be the time duration for retrievals, which could possibly move from O(log(2)(n)) to O(n) in the worst case scenario for an unbalanced data set while the hashtable would provide a constant O(1) for any data size. To counter this problem and maintain a balanced tree, a self-balancing AVL or 2-3 tree could be used instead, for which we would trade memory for performance. Another possible issue we could encounter with BST’s would be stack overflow, where the multiple non-tail recursions for most of the functions written could possibly reach that limit for a large enough tree height. To bypass this, either the algorithm will need changing to tail recursion solutions or a recursive solution avoided in preference for an iterative one.   
